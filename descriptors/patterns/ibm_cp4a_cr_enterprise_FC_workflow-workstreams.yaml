###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2020. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: workflow-workstreams
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 20.0.3
spec:
  appVersion: 20.0.3.2

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:

    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "<Required>"

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"

    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - admin.registrykey

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is required
    sc_run_as_user:

    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-jobcontainer
        tag: 20.0.3-IF002
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-dbcompatibility-initcontainer
        tag: 20.0.3-IF002
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-initcontainer
        tag: 20.0.3-IF002
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/baw/dba-umsregistration-initjob
        tag: 20.0.3-IF002

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent

    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "workflow-workstreams" pattern, which includes the following
    ## mandatory components: ban(Business Automation Navigator), ums (User Management Service), rr (Resource registry), app_engine( Application Engine) and optional components: bai
    sc_deployment_patterns: workflow-workstreams

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: bai,ae_data_persistence
    sc_optional_components: bai,ae_data_persistence

    ## The deployment type as selected by the user.  Possible values are: demo, enterprise
    sc_deployment_type: enterprise

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller.
    sc_ingress_tls_secret_name: <Required>

    ## For OCP, this is used to create route, you should input a valid hostname in the required field.
    sc_deployment_hostname_suffix: "{{ meta.namespace }}.<Required>"

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []

    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: "<Required>"

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_initialization: false
    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_verification: false

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "enterprise" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"

    # Kafka client configuration for IBM Business Automation Insights and other ICP4A products.
    #
    # The customization of the following 4 parameters is "<Required>" only if you have
    # specificed "bai" as part of the sc_optional_components to specify that Business Automation
    # Insights must be installed.
    #
    # Otherwise, if Business Automation Insights is not being installed, there is no need to configure
    # these parameters and they can be kept empty.
    ##############################################################################################
    kafka_configuration:
      # A comma-separated list of hosts:port for connection to the Kafka cluster.
      # This parameter is mandatory for any Kafka configuration.
      bootstrap_servers: "<Required>"
      # The URL of the Kafka schema registry.
      # If the Business Automation Insights processor for custom events is configured, the value of this
      # parameter must provide the URL of the schema registry. Otherwise, it can be left empty.
      schema_registry_url:
      # The type of the Kafka schema registry.
      # Valid value: APICURIO. If not set, defaults to APICURIO. If set to any other value, the processing of
      # events using Avro schema in Business Automation Insights is not possible and the BAI Management
      # service is not deployed.
      schema_registry_type:
      # The value for the Kafka security.protocol property.
      # Valid values: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. Default: SASL_SSL.
      security_protocol:
      # The value for the Kafka sasl.mechanism property.
      # Valid values: PLAIN, SCRAM-SHA-512. Default: PLAIN.
      sasl_mechanism:
      # If the Kafka server requires authentication or uses SSL communications, the value of this parameter
      # must provide the name of a Kubernetes secret that holds the following keys as base64-encoded strings:
      # kafka-username: Kafka username; leave empty if no authentication
      # kafka-password: Kafka password; leave empty if no authentication
      # kafka-server-certificate: server certificate for SSL communications; leave empty if SSL protocol is not used
      connection_secret_name:

  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"

      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3

    ## The database configuration for the document object store (DOCS) datasource for CPE
    dc_os_datasources:
    ## Object store for FNDS DOCS. Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the GCD configuration above.
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOCS non-XA datasource name.  The default value is "FNDSDOCS".
      dc_common_os_datasource_name: "FNDSDOCS"
      ## The DOCS XA datasource name.  The default value is "FNDSDOCSXA".
      dc_common_os_xa_datasource_name: "FNDSDOCSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for the target object store (TOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The TOS non-XA datasource name.  The default value is "FNDSTOS".
      dc_common_os_datasource_name: "FNDSTOS"
      ## The TOS XA datasource name.  The default value is "FNDSTOSXA".
      dc_common_os_xa_datasource_name: "FNDSTOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for the design object store (DOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOS non-XA datasource name.  The default value is "FNDSDOS".
      dc_common_os_datasource_name: "FNDSDOS"
      ## The DOS XA datasource name.  The default value is "FNDSDOSXA".
      dc_common_os_xa_datasource_name: "FNDSDOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## object store for AEOS
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The AEOS non-XA datasource name.  The default value is "AEOS".
      dc_common_os_datasource_name: "AEOS"
      ## The AEOS XA datasource name.  The default value is "AEOSXA".
      dc_common_os_xa_datasource_name: "AEOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store AEOS for CPE.  For example: "AEOSDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3

  ########################################################################
  ########   IBM Business Automation Workflow configuration     ########
  ########################################################################
  baw_configuration:
  ## The baw_configuration is a list. You can deploy multiple instances of Workflow server and assign different configurations for each instance.
  ## For each instance, baw_configuration.name and baw_configuration.name.hostname must have different values.
  - name: instance1
    ## If config the Process Portal for a federated environment and integrate with intelligent task prioritization
    host_federated_portal: true
    ## Workflow server service type.
    service_type: "Route"
    ## Workflow server hostname
    hostname: ""
    ## Workflow server port
    port: 443
    ## Workflow server nodeport
    nodeport: 30026
    ## Workflow server environment type. The possible value are "Development" or "Test" or "Staging" or "Production"
    env_type: "Production"
    ## Workflow server capability
    capabilities: "workflow,workstreams"
    ## Workflow server replica count
    replicas: 2
    ## Designate an existing LDAP user for the Workflow Server admin user.
    admin_user: "<Required>"
    ## The name of Workflow server admin secret, the secret name is optional, if the secret name is null, default secret named {{ meta.name }}-<instance-name>-baw-admin-secret will be generated
    admin_secret_name: "{{ meta.name }}-instance1-baw-admin-secret"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    # For scenario that customer has implemented their own Portal. E,g https://portal.mycompany.com
    customized_portal_endpoint: ""

    federated_portal:
      ## Content security policy additional origins for federate on premise BAW systems. E.g ["https://on-prem-baw1","https://on-prem-baw2"]
      content_security_policy_additional_origins: []
    external_connection_timeout: ""

    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:

    tls:
      ## Workflow server TLS secret that contains tls.key and tls.crt.
      tls_secret_name: ibm-baw-tls
      ## Workflow server TLS trust list.
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic baw_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want Workflow server to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic baw_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:
    image:
      ## Workflow image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server
      ## Image tag for Workflow server container
      tag: 20.0.3-IF011
      ## Pull policy for Workflow container
      pullPolicy: IfNotPresent
    pfs_bpd_database_init_job:
      ## Database initialization image repository URL for Process Federation Server
      repository: cp.icr.io/cp/cp4a/baw/pfs-bpd-database-init-prod
      ## Image tag for database initialization for Process Federation Server
      tag: 20.0.3-IF002
      ## Pull policy for Process Federation Server database initialization image
      pullPolicy: IfNotPresent
    upgrade_job:
      ## Workflow server database handling image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Image tag for Workflow server database handling
      tag: 20.0.3-IF011
      ## Pull policy for Workflow server database handling
      pullPolicy: IfNotPresent
    bas_auto_import_job:
      ## BAS toolkit init image repository URL
      repository: cp.icr.io/cp/cp4a/baw/toolkit-installer
      ## Image tag for BAS toolkit init image
      tag: 20.0.3-IF002
      ## Pull policy for BAS toolkit init image
      pullPolicy: IfNotPresent
    ibm_workplace_job:
      ## IBM Workplace deployment job image repository URL
      repository: cp.icr.io/cp/cp4a/baw/iaws-ibm-workplace
      ## Image tag for IBM Workplace deployment job image
      tag: 20.0.3-IF002
      ## Pull policy for IBM Workplace deployment job image
      pull_policy: IfNotPresent

    ## The database configuration for Workflow server
    database:
      ## Whether to enable Secure Sockets Layer (SSL) support for the Workflow server database connection
      enable_ssl: true
      ## Secret name for storing the database TLS certificate when enable SSL connections to the Workflow server databae engine. Required only when enable_ssl is true
      db_cert_secret_name: "<Required>"
      ## Workflow server database type, Possible values are: db2, oracle, postgresql
      type: "<Required>"
      ## Workflow server database server name
      server_name: "<Required>"
      ## Workflow server database name
      database_name: "<Required>"
      ## Workflow server database port. For DB2, the default value is "50000"
      port: "<Required>"
      ## Workflow server database secret name which include the database user name and password.
      secret_name: "<Required>"
      # If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      jdbc_url:
      # Set to true if using custom JDBC drivers (For example using Oracle, PostgreSQL or some special DB2 driver)
      use_custom_jdbc_drivers: false
      # The PVC name which bind to the PV which have the custom JDBC driver files stored
      custom_jdbc_pvc:
      # The custom JDBC driver files set
      jdbc_driver_files: 'db2jcc4.jar db2jcc_license_cisuz.jar db2jcc_license_cu.jar'
      ## Workflow server database connect pool maximum number of physical connections
      cm_max_pool_size: 200
      dbcheck:
        ## The maximum waiting time (seconds) to check the database intialization status
        wait_time: 900
        ## The interval time (seconds) to check.
        interval_time: 15
      hadr:
        ## Database standby host for high availability disaster recovery (HADR)
        ## To enable database HADR, configure both standby host and port
        standbydb_host:
        ## Database standby port for HADR
        standbydb_port:
        ## Retry interval for HADR
        retryinterval:
        ## Maximum retries for HADR
        maxretries:

    ## The configurations for content integration
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container
        tag: 20.0.3-IF002
        ## Pull policy for content integration container.
        pull_policy: IfNotPresent
      ## Domain name for content integration
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration
      object_store_name: "DOCS"
      ## Admin secret for content integration
      cpe_admin_secret: ""

    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: 20.0.3-IF002
        ## Pull policy for CASE init job container.
        pull_policy: IfNotPresent

      ## Domain name for CASE
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE
      object_store_name_dos: "DOS"
      ## Target Object Store name of CASE
      object_store_name_tos: "TOS"
      ## Connection point name for Target Object Store
      connection_point_name_tos: "cpe_conn_tos"

      ## Name of the target environment/project area to register with the case components and associate with an IBM Content Navigator desktop
      target_environment_name: "target_env"

      ## PVC name for CASE network shared directory
      network_shared_directory_pvc: "{{ navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore | default('icn-pluginstore', true) }}"
      ## The custom package names if need to install custom package, the value format like "package1.zip, package2,zip"
      custom_package_names: ""
      ## The custom extension names if need to install custom extension, the value format like "extension1.zip, extension2,zip"
      custom_extension_names: ""
      ## The event emitter settings if you want to enable Case Event Emitter
      event_emitter:
        date_sql:
        logical_unique_id:
        solution_list:
        emitter_batch_size:
        process_pe_events:

    ## Workflow center configuration
    workflow_center:
      ## The URL of workflow center
      url: ""
      # The secret name of workflow center that contains username and password
      secret_name: ""
      # The hearbeat interval(seconds) to connect to workflow center
      heartbeat_interval: 30
      webpd_url: ""

    ## Application engine configuration, because application engine is an array,
    ## when there is only one Application engine deployed along with this CR, below three parameters are not required.
    ## when there is more then one application engine deployed, below three parameters are required.
    appengine:
      ## App Engine hostname
      hostname: ""
      ## App Engine port
      port: "443"
      ## App Engine admin secret name
      admin_secret_name: ""

    ## The configuration for Java Messaging Service(JMS)
    jms:
      image:
        ## Image name for Java Messaging Service container
        repository: cp.icr.io/cp/cp4a/baw/jms
        ## Image tag for Java Messaging Service container
        tag: 20.0.3-IF002
        ## Pull policy for Java Messaging Service container
        pull_policy: IfNotPresent
      tls:
        ## TLS secret name for Java Message Service (JMS)
        tls_secret_name: ibm-jms-tls-secret
      resources:
        limits:
          ## Memory limit for JMS configuration
          memory: "2Gi"
          ## CPU limit for JMS configuration
          cpu: "1000m"
        requests:
          ## Requested amount of memory for JMS configuration
          memory: "512Mi"
          ## Requested amount of CPU for JMS configuration
          cpu: "200m"
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"
      ## Default values for liveness probes. Modify these values to meet your requirements.
      liveness_probe:
        initial_delay_seconds: 180
        period_seconds: 20
        timeout_seconds: 10
        failure_threshold: 3
        success_threshold: 1
      ## Default values for rediness probes. Modify these values to meet your requirements.
      readiness_probe:
        initial_delay_seconds: 30
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6
        success_threshold: 1

    ## Resource configuration for init job
    resources_init:
      limits:
        ## CPU limit
        cpu: "500m"
        ## Memory limit
        memory: 256Mi
      requests:
        ## Requested amount of CPU
        cpu: "200m"
        ## Requested amount of memory
        memory: 128Mi

    ## Resource configuration for heavy init job such as database init job
    resources_init_heavy_job:
      limits:
        ## CPU limit
        cpu: 1
        ## Memory limit
        memory: 1536Mi
      requests:
        ## Requested amount of CPU
        cpu: "500m"
        ## Requested amount of memory
        memory: 512Mi

    ## Resource configuration
    resources:
      limits:
        ## CPU limit for Workflow server.
        cpu: 4
        ## Memory limit for Workflow server
        memory: 3Gi
      requests:
        ## Requested amount of CPU for Workflow server
        cpu: "500m"
        ## Requested amount of memory for Workflow server.
        memory: 1048Mi

    ## liveness and readiness probes configuration
    probe:
      ws:
        liveness_probe:
          ## Number of seconds after the Workflow server container starts before the liveness probe is initiated
          initial_delay_seconds: 300
          ## Number of seconds to wait before the next probe.
          period_seconds: 10
          ## Number of seconds after which the probe times out.
          timeout_seconds: 10
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 3
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
        readinessProbe:
          ## Number of seconds after the Workflow server container starts before the readiness probe is initiated
          initial_delay_seconds: 240
          ## Number of seconds to wait before the next probe.
          period_seconds: 5
          ## Number of seconds after which the probe times out.
          timeout_seconds: 5
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 6
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format.
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      # Maximum number of log files that are kept before the oldest file is removed
      max_files: 10
      # The maximum size (in MB) that a log file can reach before it is rolled.
      max_filesize: 50

    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_dumpstore
      use_dynamic_provisioning: true
      ## The persistent volume claim for logs
      existing_pvc_for_logstore: ""
      ## The minimum size of the persistent volume used mounted as log store
      size_for_logstore: "10Gi"
      ## The persistent volume claim for dump files
      existing_pvc_for_dumpstore: ""
      ## The minimum size of the persistent volume used mounted as dump store
      size_for_dumpstore: "10Gi"
      ## The persistent volume claim for generic files
      existing_pvc_for_filestore: ""
      ## The minimum size of the persistent volume used mounted as generic file store
      size_for_filestore: "10Gi"

    ## autoscaling
    autoscaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      target_cpu_utilization_percentage: 80

    ## customize environment settings
    environment_config:
      ## Whether to show intelligent task prioritization service toggle button in web UI to allow task user enable/disable task prioritization service
      show_task_prioritization_service_toggle: false
      ## By default, it is false. If 'always_run_task_prioritization_service' is set to true, the value of the 'show_task_prioritization_service_toggle' is ignored and the toggle is not displayed to the user.
      always_run_task_prioritization_service: false
      csrf:
        ## Acceptable values in the Origin header field. The value of this property must be a comma-separated list of prefixes in the format protocol://host:port, e.g "https://example.com, http://example2.com:8080".
        origin_whitelist:
        ## Acceptable values in the Referer header field. The value of this property must be a comma-separated list of fully qualified host names, e.g "example1.com, example2.com".
        referer_whitelist:

    ## federation config
    federation_config:
      workflow_server:
          ## Number of primary shards of the Elasticsearch index used to store workflow server data
          index_number_of_shards: 3
          ## Number of shards replicas of the Elasticsearch index used to store workflow server data
          index_number_of_replicas: 1
      case_manager:
          - object_store_name: TOS
            ## Number of primary shards of the Elasticsearch index used to store Case Manager object store data
            index_number_of_shards: 3
            ## Number of shards replicas of the Elasticsearch index used to store Case Manager object store data
            index_number_of_replicas: 1

    ## JVM options separated with space, for example: -Dtest1=test -Dtest2=test2
    jvm_customize_options:

    ##  Workflow server custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    liberty_custom_xml:

    ##  Workflow server custom XML secret name that contains custom configuraiton in Liberty server.xml
    custom_xml_secret_name:

    ##  Workflow server Lombardi custom XML secret name that contains custom configuraiton in 100Custom.xml
    lombardi_custom_xml_secret_name:

    ##  IBM Business Automation Insights integration configuration
    business_event:
      enable: false
      enable_task_record: true
      ## set it to true when Business Automation Machine Learning Server configuration is enabled as well
      enable_task_api: false
      subscription:
      - {'app_name': '*','version': '*','component_type': '*','component_name': '*','element_type': '*','element_name': '*','nature': '*'}

  ##################################################################################
  ########   IBM Business Automation Machine Learning Server configuration  ########
  ##################################################################################
  baml_configuration:
    ## Intelligent Task Prioritization configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true
    intelligent_task_prioritization:
      ## Intelligent Task Prioritization replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Intelligent Task Prioritization container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      ## Image name for Intelligent Task Prioritization container
      image:
        repository: cp.icr.io/cp/cp4a/baw/bui-task-prioritization
        ## Image tag for Intelligent Task Prioritization container
        tag: 20.0.3-IF002
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for Intelligent Task Prioritization container
          cpu: "2"
          ## Memory limit for Intelligent Task Prioritization container
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for Intelligent Task Prioritization container
          cpu: "500m"
          ## Requested amount of memory for Intelligent Task Prioritization container
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_trained_pipelines
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
        ## The persistent volume claim for Intelligent Task Prioritization trained piplines files
        existing_pvc_for_trained_pipelines: ""
        ## The minimum size of the persistent volume used mounted as Intelligent Task Prioritization trained piplines files
        size_for_trained_pipelines: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
    ## Workforce Insights configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true and bai_configuration.bpmn.forceElasticsearchTimeseries to true
    workforce_insights:
      ## Workforce Insights replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Workforce Insights pod container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      image:
        repository: cp.icr.io/cp/cp4a/baw/workforce-insights
        tag: 20.0.3-IF002
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for workforce insights
          cpu: "2"
          ## Memory limit for workforce insights
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for workforce insights
          cpu: "500m"
          ## Requested amount of memory for workforce insights
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80

  ########################################################################
  ########   IBM Process Federation Server configuration          ########
  ########################################################################
  pfs_configuration:
    ## Process Federation Server hostname
    hostname: ""
    ## Process Federation Server port
    port: 443
    ## How the HTTPS endpoint service should be published. Possible values are ClusterIP, NodePort, Route
    service_type: Route

    ## If use the external elasticsearch server, provide the following configuration
    elasticsearch:
      ## The endpoint of external elasticearch, such as: https://<external_es_host>:<external_es_port>
      endpoint: ""
      ## The external elasticsearch administrative secret that contains the username, password and .htpasswd.
      admin_secret_name: ""
      connect_timeout: 10s
      read_timeout: 30s
      thread_count: 0

    image:
      ## Process Federation Server image
      repository: cp.icr.io/cp/cp4a/baw/pfs-prod
      ## Process Federation Server image tag
      tag: 20.0.3-IF011
      ## Process Federation Server image pull policy
      pull_policy: IfNotPresent

    ## Number of initial Process Federation Server pods
    replicas: 1
    ## Service account name for Process Federation Server pod
    service_account:
    ## Whether Kubernetes can (soft) or must not (hard) deploy Process Federation Server pods onto the same node. Possible values are "soft" and "hard".
    anti_affinity: hard

    ## Whether to enable default security roles  and possible values are: true and false
    enable_default_security_roles: true
    ## Name of the secret containing the Process Federation Server administration passwords, such as ltpaPassword, oidcClientPassword, sslKeyPassword
    admin_secret_name: ibm-pfs-admin-secret
    ## Name of the secret containing the files that will be mounted in the /config/configDropins/overrides folder
    config_dropins_overrides_secret: ""
    ## Name of the secret containing the files that will be mounted in the /config/resources/security folder
    resources_security_secret: ""
    ## Name of the custom libraries containing the files that will be mounted in the /config/resources/libs folder
    custom_libs_pvc: ""
    ## Whether to enable notification server and possible values are: true and false
    enable_notification_server: true
    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:

    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    tls:
      ## Existing TLS secret containing tls.key and tls.crt
      tls_secret_name:
      ## Existing TLS trust secret list
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic pfs_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want PFS server to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic pfs_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:

    resources:
      requests:
        ## Requested amount of CPU for PFS configuration
        cpu: 500m
        ## Requested amount of memory for PFS configuration
        memory: 512Mi
      limits:
        ## CPU limit for PFS configuration
        cpu: 2
        ## Memory limit for PFS configuration
        memory: 4Gi

    liveness_probe:
      ## Number of seconds after Process Federation Server container starts before the liveness probe is initiated
      initial_delay_seconds: 300
    readiness_probe:
      ## Number of seconds after Process Federation Server container starts before the readiness probe is initiated
      initial_delay_seconds: 240

    saved_searches:
      ## Name of the Elasticsearch index used to store saved searches
      index_name: ibmpfssavedsearches
      ## Number of shards of the Elasticsearch index used to store saved searches
      index_number_of_shards: 3
      ## Number of replicas (pods) of the Elasticsearch index used to store saved searches
      index_number_of_replicas: 1
      ## Batch size used when retrieving saved searches
      index_batch_size: 100
      ## Amount of time before considering an update lock as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      update_lock_expiration: 5m
      ## Amount of time before considering a unique constraint as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      unique_constraint_expiration: 5m

    security:
      sso:
        ## The ssoDomainNames property of the <webAppSecurity> tag
        domain_name:
        ## The ssoCookieName property of the <webAppSecurity> tag
        cookie_name: "ltpatoken2"
        ltpa:
          ## The keysFileName property of the <ltpa> tag
          filename: "ltpa.keys"
          ## The expiration property of the <ltpa> tag
          expiration: "120m"
          ## The monitorInterval property of the <ltpa> tag
          monitor_interval: "60s"
      ## The sslProtocol property of the <ssl> tag used as default SSL config
      ssl_protocol: SSL

    executor:
      ## Value of the maxThreads property of the <executor> tag
      max_threads: "80"
      ## Value of the coreThreads property of the <executor> tag
      core_threads: "40"

    rest:
      ## Value of the userGroupCheckInterval property of the <ibmPfs_restConfig> tag
      user_group_check_interval: "300s"
      ## Value of the systemStatusCheckInterval property of the <ibmPfs_restConfig> tag
      system_status_check_interval: "60s"
      ## Value of the bdFieldsCheckInterval property of the <ibmPfs_restConfig> tag
      bd_fields_check_interval: "300s"

    custom_env_variables:
      ## Names of the custom environment variables defined in the secret referenced in pfs.customEnvVariables.secret
      names:
      # - name: MY_CUSTOM_ENVIRONMENT_VARIABLE
      ## Secret holding custom environment variables
      secret:

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      storage:
        ## Use Dynamic Provisioning for PFS Logs Data Storage
        use_dynamic_provisioning: true
        ## The minimum size of the persistent volume used mounted as PFS Liberty server /logs folder
        size: 5Gi
        ## Storage class of the persistent volume used mounted as PFS Liberty server /logs folder
        storage_class: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname }}"
        existing_pvc_name: ""

    ## When PFS is deployed in a environment that includes the Resource Registry ,
    ## the following additional parameters can be used to configure the integration between PFS and the Resource Registry
    dba_resource_registry:
      ## Time to live of the lease that creates the PFS entry in the DBA Resource Registry, in seconds.
      lease_ttl: 120
      ## The interval at which to check that PFS is running, in seconds.
      pfs_check_interval: 10
      ## The number of seconds after which PFS will be considered as not running if no connection can be perfomed
      pfs_connect_timeout: 10
      ## The number of seconds after which PFS will be considered as not running if has not yet responded
      pfs_response_timeout: 30
      ## The key under which PFS should be registered in the DBA Service Registry when running
      pfs_registration_key: /dba/appresources/IBM_PFS/PFS_SYSTEM
      resources:
        limits:
          ## Memory limit for PFS and RR integration pod
          memory: '512Mi'
          ## CPU limit for PFS and RR integration pod
          cpu: '500m'
        requests:
          ## Requested amount of memory for PFS and RR integration pod
          memory: '512Mi'
          ## Requested amount of CPU for PFS and RR integration pod
          cpu: '200m'

  ########################################################################
  ########   Embedded Elasticsearch configuration                 ########
  ########################################################################
  elasticsearch_configuration:
    es_image:
      ## Elasticsearch image
      repository: cp.icr.io/cp/cp4a/baw/pfs-elasticsearch-prod
      ## Elasticsearch image tag
      tag: 20.0.3-IF011
      ## Elasticsearch image pull policy
      pull_policy: IfNotPresent
    es_init_image:
      ## The image used by the privileged init container to configure Elasticsearch system settings.
      ## This value is only relevant if elasticsearch_configuration.privileged is set to true
      repository: cp.icr.io/cp/cp4a/baw/pfs-init-prod
      ## The image tag for Elasticsearch init container
      tag: 20.0.3-IF002
      ## The pull policy for Elasticsearch init container
      pull_policy: IfNotPresent
    es_nginx_image:
      ## The name of the Nginx docker image to be used by Elasticsearch pods
      repository: cp.icr.io/cp/cp4a/baw/pfs-nginx-prod
      ## The image tag of the Nginx docker image to be used by Elasticsearch pods
      tag: 20.0.3-IF002
      ## The pull policy for the Nginx docker image to be used by Elasticsearch pods
      pull_policy: IfNotPresent

    ## Number of initial Elasticsearch pods
    replicas: 1
    ## How the HTTPS endpoint service should be published. The possible values are ClusterIP and NodePort
    service_type: ClusterIP
    ## The port to which the Elasticsearch server HTTPS endpoint will be exposed externally.
    ## This parameter is relevant only if elasticsearch_configuration.service_type is set to NodePort
    external_port:
    ## The elasticsearch admin secret that contains the username, password and .htpasswd.
    ## If not provided, the defualt admin secret named "{{ meta.name }}-elasticsearch-admin-secret" is used.
    admin_secret_name:
    ## Whether Kubernetes "may" (soft) or "must not" (hard) deploy Elasticsearch pods onto the same node
    ## The possible values are "soft" and "hard"
    anti_affinity: hard
    ## The Elasticsearch pods require the hosting worker nodes to be configured to:
    ## - disable memory swapping by setting the sysctl value vm.swappiness to 1.
    ## - increase the limit on the number of open files descriptors for the user running Elasticsearch by setting sysctl value vm.max_map_count to 65,536 or higher.
    ## When set to true, a privileged init container will execute the appropriate sysctl commands to update the worker node configuration to match Elasticsearch requirements.
    ## When set to false, you must ask the cluster administrator to change the memory swapping and descriptor properties on each worker node.
    privileged: false
    ## If elasticsearch_configuration.privileged is set to true, you must create a service account that has the privileged SecurityContextConstraint to allow running privileged containers. Refer to Knowledge Center for more info.
    ## If elasticsearch_configuration.service_account not set, default service account "{{ meta.name }}-elasticsearch-service-account" will be used.
    service_account: "<Required>"
    ## Initial delay for liveness and readiness probes of Elasticsearch pods
    probe_initial_delay: 90
    ## The JVM heap size to allocate to each Elasticsearch pod
    heap_size: "1024m"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    resources:
      limits:
        ## Memory limit for Elasticsearch configuration
        memory: "2Gi"
        ## CPU limit for Elasticsearch configuration
        cpu: "1000m"
      requests:
        ## Requested amount of memory for Elasticsearch configuration
        memory: "2Gi"
        ## Requested amount of CPU for Elasticsearch configuration
        cpu: "100m"

    storage:
      ## If persistent the elasticsearch data. Set to false for non-production or trial-only deployment.
      persistent: true
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 10Gi
      ## Storage class name for Elasticsearch persistent storage
      storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

    snapshot_storage:
      ## If persistent the elasticsearch snapshot storage. Set to true for production deployment.
      enabled: false
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 30Gi
      ## Storage class name for Elasticsearch persistent snapshot storage
      storage_class_name: ""
      ## By default, a new persistent volume claim is be created. Specify an existing claim here if one is available.
      existing_claim_name: ""

  ########################################################################
  ########  IBM FileNet Content Manager initialize configuration  ########
  ########################################################################
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      ## Provide a name for the domain
      domain_name: "P8DOMAIN"
      ## The encryption strength
      encryption_key: "128"
    ic_ldap_creation:
      ## Administrator user
      ic_ldap_admin_user_name:
      - "CEAdmin"
      ## Administrator group
      ic_ldap_admins_groups_name:
      - "P8Administrators"
      ## Name of the LDAP directory
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      ## Configuration for the document object store
      ## Display name for the document object store to create
      - oc_cpe_obj_store_display_name: "DOCS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOCS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOCS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOCS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOCSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "docs_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

      ## Configuration for the design object store
      ## Display name for the design object store to create
      - oc_cpe_obj_store_display_name: "DOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "dos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 2
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

      ## Configuration for the target object store
      ## Display name for the target object store to create
      - oc_cpe_obj_store_display_name: "TOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "TOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
         ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "tos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "cpe_conn_tos"
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

      ## Configuration for the application engine object store
      ## Display name for the application engine object store to create
      - oc_cpe_obj_store_display_name: "AEOS"
        ## Symbolic name for the application engine object store to create
        oc_cpe_obj_store_symb_name: "AEOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "AEOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "AEOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "AEOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/osae_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "aeos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

  ########################################################################
  ########      IBM Business Automation Insights configuration    ########
  ########################################################################
  bai_configuration:
    imageCredentials:
      registry: cp.icr.io/cp/cp4a

    # Set to true to automatically create the OpenShift routes when sc_deployment_platform is set
    # to OCP or ROKS.
    createRoutes: false

    # Set to true to enable the Flink job for sending events to HDFS.
    ingestion:
      install: false

    # Set to false to disable the Flink job for BAW.
    bpmn:
      install: true

    # Set to true to enable the Flink job for BAWAdv.
    bawadv:
      install: false

    # Set to false to disable the Flink job for ICM.
    icm:
      install: true

    # Set to true to enable the Flink job for ODM.
    odm:
      install: false

    # Set to true to enable the Flink job for Content.
    content:
      install: false
